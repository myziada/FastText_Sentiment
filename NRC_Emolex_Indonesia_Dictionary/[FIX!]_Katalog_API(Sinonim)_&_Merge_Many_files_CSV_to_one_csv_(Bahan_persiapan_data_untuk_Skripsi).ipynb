{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# importing the module\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# open the file in read mode\n",
        "filename = open('/content/sample_data/Dataset_katalogAPI_Takut/dataset_takut.csv', 'r') #panggil file pada directori file nya\n",
        "\n",
        "# creating dictreader object\n",
        "file = csv.DictReader(filename)\n",
        "\n",
        "# creating empty lists\n",
        "daftar_kosa_kata = []\n",
        "\n",
        "\n",
        "# iterating over each row and append\n",
        "# values to empty list\n",
        "for col in file:\n",
        "    daftar_kosa_kata.append(col['word'])\n",
        "\n",
        "# printing lists\n",
        "print('word:', daftar_kosa_kata)\n",
        "#data ter-print seperti dibawah ini\n",
        "#'gelisah', 'takwa', 'zan', 'geriap', 'jeri', 'berkecil hati', 'lasi', 'bernyali kecil', 'tercemas', 'mamang', 'kecut', 'segan', 'cuak', 'kirik', 'kecut hati', 'bimbang', 'dahsyat', 'gidik', 'keder', 'cemas', 'gemang', 'gamang', 'kimput', 'gentar', 'ciut', 'kecil hati'\n",
        "#Masukkan hasil print tersebut ke daftar_kosa_kata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MulzF70Piimd",
        "outputId": "a79e6ea8-9387-4070-b150-68c257b25c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word: ['gelisah', 'takwa', 'zan', 'geriap', 'jeri', 'berkecil hati', 'lasi', 'bernyali kecil', 'tercemas', 'mamang', 'kecut', 'segan', 'cuak', 'kirik', 'kecut hati', 'bimbang', 'dahsyat', 'gidik', 'keder', 'cemas', 'gemang', 'gamang', 'kimput', 'gentar', 'ciut', 'kecil hati']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setelah masukkan ke daftar_kosa_kata dibawah ini, jalankan kode ini\n",
        "daftar_kosa_kata = ['gelisah', 'takwa', 'zan', 'geriap', 'jeri', 'berkecil hati', 'lasi', 'bernyali kecil', 'tercemas', 'mamang', 'kecut', 'segan', 'cuak', 'kirik', 'kecut hati', 'bimbang', 'dahsyat', 'gidik', 'keder', 'cemas', 'gemang', 'gamang', 'kimput', 'gentar', 'ciut', 'kecil hati']\n",
        "\n",
        "\n",
        "def generate_dataset(kosa_kata):\n",
        "    file_name = \"/content/sample_data/Dataset_katalogAPI_Takut/dataset_katalogApi_Takut_\" + kosa_kata + \".csv\"\n",
        "    # file_name = \"dataset_katalogApi_sedih.csv\"\n",
        "    # Menentukan daftar kosa kata sinonim yang mau di generate\n",
        "    # (kateglo/relation/s)\n",
        "    # Ambil data sinonim dari API\n",
        "\n",
        "    url = \"http://kateglo.lostfocus.org/api.php?format=json&phrase=\" + kosa_kata\n",
        "\n",
        "    payload = {}\n",
        "    headers = {}\n",
        "\n",
        "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
        "\n",
        "    # print(response.text)\n",
        "    # Mengubah string menjadi dictionary\n",
        "    # Python3 code to demonstrate\n",
        "    # convert dictionary string to dictionary\n",
        "    # using json.loads()\n",
        "\n",
        "    # initializing string\n",
        "\n",
        "    # printing original string\n",
        "\n",
        "    # using json.loads()\n",
        "    # convert dictionary string to dictionary\n",
        "    res = json.loads(response.text)\n",
        "    daftar_data_sinonim = res[\"kateglo\"][\"relation\"][\"s\"]\n",
        "    daftar_kata_sinonim = []  # disimpen data related_phrase disini\n",
        "    jumlah_kata_sinonim = res[\"kateglo\"][\"relation\"][\"relation_reverse\"]\n",
        "    # print result\n",
        "    # print(jumlah_kata_sinonim)\n",
        "    for index in range(jumlah_kata_sinonim+1):\n",
        "        index = str(index)\n",
        "        # print(index)\n",
        "        daftar_kata_sinonim.append(\n",
        "            daftar_data_sinonim[index][\"related_phrase\"])\n",
        "    print(daftar_kata_sinonim)\n",
        "    # struktur dictionary dataset yang mau disimpan\n",
        "    # ubah dictionary menjadi csv\n",
        "\n",
        "    employee_info = ['word', 'val']\n",
        "\n",
        "    new_dict = []\n",
        "    for sinonim in daftar_kata_sinonim:\n",
        "        new_dict.append(\n",
        "            {'word': sinonim, 'val': '1'}\n",
        "        )\n",
        "\n",
        "    with open(file_name, 'w') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=employee_info)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(new_dict)\n",
        "\n",
        "    import re\n",
        "    import io\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    with open(file_name, 'r') as f:\n",
        "        data = f.read()\n",
        "        df = pd.read_csv(io.StringIO(re.sub('\"\\s*\\n', '\"', data)))\n",
        "\n",
        "    for col in df.columns:  # To replace all line breaks in all textual columns\n",
        "        if df[col].dtype == np.object_:\n",
        "            df[col] = df[col].str.replace('\\n', '')\n",
        "    df.to_csv(file_name)\n",
        "    # simpan csv di folder dictionary_dataset\n",
        "\n",
        "\n",
        "for kosa_kata in daftar_kosa_kata:\n",
        "    generate_dataset(kosa_kata)\n",
        "    print(\"Berhasil membuat dataset \"+kosa_kata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bml86iIZPWuy",
        "outputId": "85566031-67d2-4ef8-de23-d3b742bc57f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['asan tak asan', 'bergolak', 'bergundang', 'bingung', 'cemas', 'gelebah', 'gerah', 'karut', 'kelesah', 'kelusuh-kelasah', 'khawatir', 'meranyah', 'nyanyang', 'pusang', 'resah', 'rewel', 'risau', 'samar', 'selempang', 'semak hati', 'takut', 'uring-uringan', 'was-was', 'galau', 'berkarut']\n",
            "Berhasil membuat dataset gelisah\n",
            "['ketaatan', 'kesalihan', 'takut']\n",
            "Berhasil membuat dataset takwa\n",
            "['curiga', 'syak']\n",
            "Berhasil membuat dataset zan\n",
            "['bergidik']\n",
            "Berhasil membuat dataset geriap\n",
            "['bimbang']\n",
            "Berhasil membuat dataset jeri\n",
            "['takut', 'bermasam muka']\n",
            "Berhasil membuat dataset berkecil hati\n",
            "['jera']\n",
            "Berhasil membuat dataset lasi\n",
            "['takut']\n",
            "Berhasil membuat dataset bernyali kecil\n",
            "['khawatir']\n",
            "Berhasil membuat dataset tercemas\n",
            "['bingung', 'ketakutan', 'takut', 'cemas']\n",
            "Berhasil membuat dataset mamang\n",
            "['cemberut', 'kedut', 'kerut', 'lisut', 'merinding', 'takut', 'gidik', 'hampa']\n",
            "Berhasil membuat dataset kecut\n",
            "['enggan', 'takut', 'angkat topi', 'ogah', 'canggung', 'ogah-ogahan', 'lenggana', 'malas', 'hebat', 'sungkan', 'gamak', 'hormat', 'celih', 'tergamak', 'janggal', 'berat ekor']\n",
            "Berhasil membuat dataset segan\n",
            "['bergidik', 'cabar hati', 'ciut']\n",
            "Berhasil membuat dataset cuak\n",
            "['mengirik']\n",
            "Berhasil membuat dataset kirik\n",
            "['gentar', 'takut']\n",
            "Berhasil membuat dataset kecut hati\n",
            "['bengap', 'berganti-ganti', 'bingung', 'buncah', 'cemas', 'curiga', 'empot-empotan', 'galau', 'gamam', 'gelisah', 'gentar', 'goyah', 'kacau', 'khawatir', 'kusut', 'limbung', 'mendua hati']\n",
            "Berhasil membuat dataset bimbang\n",
            "['amat sangat', 'azmat', 'bahana', 'bingung', 'hebat', 'kebingungan', 'ketakutan']\n",
            "Berhasil membuat dataset dahsyat\n",
            "['bergidik']\n",
            "Berhasil membuat dataset gidik\n",
            "['gemetar', 'gentar', 'kimput', 'takut', 'cuak', 'geriap']\n",
            "Berhasil membuat dataset keder\n",
            "['asan tak asan', 'berwalang hati', 'bingung', 'cemas-cemas', 'empot-empotan', 'galau', 'gamang', 'gelebah']\n",
            "Berhasil membuat dataset cemas\n",
            "['gamang', 'ngeri', 'takut']\n",
            "Berhasil membuat dataset gemang\n",
            "['gayat', 'khawatir', 'ngeri', 'takut', 'gentar', 'gemang', 'geriap', 'singunen', 'gidik', 'ayal', 'cemas']\n",
            "Berhasil membuat dataset gamang\n",
            "['gentar', 'takut', 'cuak', 'gidik']\n",
            "Berhasil membuat dataset kimput\n",
            "['cabar hati', 'ciut', 'gamang', 'gecar', 'geletar', 'gerak', 'getar', 'giris']\n",
            "Berhasil membuat dataset gentar\n",
            "['bergidik', 'cabar hati', 'cuak', 'gamang']\n",
            "Berhasil membuat dataset ciut\n",
            "['kecewa', 'marah', 'takut', 'gidik', 'gusar', 'ciut', 'cuak', 'gentar', 'geriap']\n",
            "Berhasil membuat dataset kecil hati\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gabungkan banyak file csv menjadi 1 file csv\n",
        "import os, glob\n",
        "import pandas as pd\n",
        "\n",
        "path = \"/content/sample_data/Dataset_katalogAPI_Jijik\"\n",
        "\n",
        "all_files = glob.glob(os.path.join(path, \"dataset_katalogApi_*.csv\"))\n",
        "df_from_each_file = (pd.read_csv(f, sep=',') for f in all_files)\n",
        "df_merged   = pd.concat(df_from_each_file, ignore_index=True)\n",
        "df_merged.drop('Unnamed: 0', axis = 1, inplace = True)#untuk menghapus colom unnamed (karna pada kolom tersebut tidak diperlukan)\n",
        "df_merged.to_csv( \"/content/sample_data/Dataset_katalogAPI_Jijik/Emolex+KatalogApi_Jijik.csv\")"
      ],
      "metadata": {
        "id": "0acKxgBbELsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tidak digunakan karena sudah cukup menggunakan kode diatas untuk menggabungkan banyak file csv menjadi 1 file csv.\n",
        "# tidak perlu digunakan kode ini, karena kode diatas lebih sesuai dengan yang dibutuhkan pada format kolom dataset kamus untuk persiapan labelin lexicon untuk skripsi\n",
        "# def get_df():\n",
        "#     df=pd.DataFrame()\n",
        "#     os.chdir(\"/content/sample_data/Dataset_katalogAPI_Marah\")\n",
        "#     for file in os.listdir():\n",
        "#         if file.endswith('.csv'):\n",
        "#             aux=pd.read_csv(file, error_bad_lines=False)\n",
        "#             df=df.append(aux)\n",
        "#     return df\n",
        "\n",
        "\n",
        "# df=get_df()\n",
        "# df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "# df.to_csv(f\"file_name1.csv\")"
      ],
      "metadata": {
        "id": "ajzv3wAtHA6A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}